{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 2: Sample Construction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's import a few common modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python â‰¥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "import random\n",
    "seed_val = 43\n",
    "np.random.seed(seed_val)\n",
    "random.seed(seed_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "df = pd.read_csv(\"datasets/aca_21-23.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separating Test-set from Train-set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Strafied sampling (train-set : test_set = 80:20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "seed = 42\n",
    "\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=seed)\n",
    "for train_index, test_index in split.split(df, df['is_drop']):\n",
    "    train_set = df.loc[train_index]\n",
    "    test_set = df.loc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.reset_index(inplace=True, drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.set_index(train_set['index'], inplace=True)\n",
    "train_set.drop(['index'], axis=1, inplace=True)\n",
    "train_set.index.name = 'index_o'\n",
    "train_set.to_csv(f'datasets/train_set_{seed}.csv', na_rep='NULL', encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set.index.name = 'index_o'\n",
    "test_set.to_csv(f'datasets/test_set_{seed}.csv', na_rep='NULL', encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function filtering out invalid samples\n",
    "* Horizon: from [t_begin] to [t_end] (remove t=0 dropout samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(df, t_begin, t_end, drop_t0):\n",
    "    if (drop_t0 == 1):\n",
    "        if (t_begin == 0): raise ValueError\n",
    "        df = df.loc[~df['state_now'].isin([1,2]), :]\n",
    "\n",
    "    if (t_end == 1):\n",
    "        no_next = (df['year'] == 2023) & (df['semester'] == 2)\n",
    "    elif (t_end == 2):\n",
    "        no_next = (df['year'] == 2023)\n",
    "    elif (t_end == 3):\n",
    "        no_next = (df['year'] == 2023) | ((df['year'] == 2022) & (df['semester'] == 2))\n",
    "\n",
    "    if (t_end != 0):\n",
    "        df = df.loc[~no_next, :]\n",
    "\n",
    "    if (t_end == 0):\n",
    "        if (t_begin != 0): raise ValueError\n",
    "        is_leave = (df['state_now'].isin([3]))\n",
    "        is_drop = (df['state_now'].isin([2]))\n",
    "    elif (t_end == 1):\n",
    "        if (t_begin == 0):\n",
    "            is_leave = (df['state_now'].isin([3])) #& (df['state_next_1'].isin([3]))\n",
    "        else:\n",
    "            is_leave = (df['state_next_1'].isin([3]))\n",
    "    elif (t_end == 2):\n",
    "        if (t_begin == 0):\n",
    "            is_leave = (df['state_now'].isin([3])) #& (df['state_next_1'].isin([3])) & (df['state_next_2'].isin([3]))\n",
    "        else:\n",
    "            is_leave = (df['state_next_1'].isin([3])) #& (df['state_next_2'].isin([3]))\n",
    "    elif (t_end == 3):\n",
    "        if (t_begin == 0):\n",
    "            is_leave = (df['state_now'].isin([3])) #& (df['state_next_1'].isin([3])) & (df['state_next_2'].isin([3])) & (df['state_next_3'].isin([3]))\n",
    "        else:\n",
    "            is_leave = (df['state_next_1'].isin([3])) #& (df['state_next_2'].isin([3])) & (df['state_next_3'].isin([3]))\n",
    "\n",
    "    if (t_end != 0):\n",
    "        dataset = df.loc[~is_leave].copy()\n",
    "    else:\n",
    "        dataset =df\n",
    "\n",
    "    if (t_end == 0):\n",
    "        if (t_begin != 0): raise ValueError\n",
    "        is_drop = (dataset['state_now'].isin([2]))\n",
    "    elif (t_end == 1):\n",
    "        if (t_begin == 0):\n",
    "            is_drop = (dataset['state_now'].isin([2])) | (dataset['state_next_1'].isin([2]))\n",
    "        else:\n",
    "            is_drop = (dataset['state_next_1'].isin([2]))\n",
    "    elif (t_end == 2):\n",
    "        if (t_begin == 0):\n",
    "            is_drop = (dataset['state_now'].isin([2])) | (dataset['state_next_1'].isin([2])) | (dataset['state_next_2'].isin([2]))\n",
    "        else:\n",
    "            is_drop = (dataset['state_next_1'].isin([2])) | (dataset['state_next_2'].isin([2]))\n",
    "    elif (t_end == 3):\n",
    "        if (t_begin == 0):\n",
    "            is_drop = (dataset['state_now'].isin([2])) | (dataset['state_next_1'].isin([2])) | (dataset['state_next_2'].isin([2])) | (dataset['state_next_3'].isin([2]))\n",
    "        else:\n",
    "            is_drop = (dataset['state_next_1'].isin([2])) | (dataset['state_next_2'].isin([2])) | (dataset['state_next_3'].isin([2]))\n",
    "\n",
    "    dataset.loc[~is_drop.values, 'is_drop'] = 0\n",
    "    dataset.loc[is_drop.values, 'is_drop'] = 1\n",
    "\n",
    "    dataset.reset_index(inplace=True, drop=True)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For $t=1, 2, 3$, filtering out invalid samples and saving the final \"train-sets\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "df = pd.read_csv(f\"datasets/train_set_{seed}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t_end=1, train_set size: (31038, 16)\n",
      "t_end=2, train_set size: (25406, 16)\n",
      "t_end=3, train_set size: (18384, 16)\n"
     ]
    }
   ],
   "source": [
    "train_set = {}\n",
    "for t_end in {1, 2, 3}:\n",
    "    train_set[t_end] = prepare_dataset(df, t_begin=1, t_end=t_end, drop_t0=1)\n",
    "    train_set[t_end].drop(columns=['state_now', 'state_next_1', 'state_next_2', 'state_next_3'], inplace=True)\n",
    "    print(f\"t_end={t_end}, train_set size: {train_set[t_end].shape}\")\n",
    "    train_set[t_end].reset_index(inplace=True, drop=True)\n",
    "    train_set[t_end].to_csv(f\"datasets/train_set_{seed}_t_{t_end}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For $t=1, 2, 3$, filtering out invalid samples and saving the final \"test-sets\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f\"datasets/test_set_{seed}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14815 entries, 0 to 14814\n",
      "Data columns (total 20 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   index_o            14815 non-null  int64  \n",
      " 1   year               14815 non-null  int64  \n",
      " 2   semester           14815 non-null  int64  \n",
      " 3   grade              14815 non-null  int64  \n",
      " 4   sex                14815 non-null  object \n",
      " 5   gpa_last_seme      14815 non-null  float64\n",
      " 6   credits_last_seme  14815 non-null  float64\n",
      " 7   credits_tot        14815 non-null  float64\n",
      " 8   n_seme             14815 non-null  int64  \n",
      " 9   years_since        14815 non-null  int64  \n",
      " 10  state_next_1       11016 non-null  float64\n",
      " 11  state_next_2       7984 non-null   float64\n",
      " 12  state_next_3       4778 non-null   float64\n",
      " 13  state_now          14815 non-null  int64  \n",
      " 14  college            14815 non-null  object \n",
      " 15  adm_unit           14815 non-null  int64  \n",
      " 16  nation             14815 non-null  int64  \n",
      " 17  in_capa            14815 non-null  bool   \n",
      " 18  leave              14815 non-null  bool   \n",
      " 19  is_drop            14815 non-null  float64\n",
      "dtypes: bool(2), float64(7), int64(9), object(2)\n",
      "memory usage: 2.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t_end=1, test_set size: (7776, 16)\n",
      "t_end=2, test_set size: (6363, 16)\n",
      "t_end=3, test_set size: (4637, 16)\n"
     ]
    }
   ],
   "source": [
    "test_set = {}\n",
    "for t_end in {1, 2, 3}:\n",
    "    test_set[t_end] = prepare_dataset(df, t_begin=1, t_end=t_end, drop_t0=1)\n",
    "    test_set[t_end].drop(columns=['state_now', 'state_next_1', 'state_next_2', 'state_next_3'], inplace=True)\n",
    "    print(f\"t_end={t_end}, test_set size: {test_set[t_end].shape}\")\n",
    "    test_set[t_end].reset_index(inplace=True, drop=True)\n",
    "    test_set[t_end].to_csv(f\"datasets/test_set_{seed}_t_{t_end}.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.1)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
